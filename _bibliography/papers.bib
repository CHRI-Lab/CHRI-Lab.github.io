%%%%% 2024 
@article{schombs2024exploring,
  title={Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations},
  author={Sch{\"o}mbs, Sarah and Goncalves, Jorge and Johal, Wafa},
  journal={arXiv preprint arXiv:2402.04598},
  pdf = {https://chri-lab.github.io/files/papers/schombs2023.pdf},
  year={2024}
}

@article{pan2024,
  title={Exploring the Effects of Shared Autonomy on Cognitive Load and Trust in Human-Robot Interaction},
  author={Pan, Jiahe and Eden, Jon and Oetomo, Denny and Johal, Wafa},
  journal={Robotics and Automation Letters},
  volume={},
  pages={},
  year={2024},
  publisher={IEEE},
  selected = 	 {yes}
}

@inproceedings{schombs2024b,
  author = {Sch{\"o}mbs, Sarah and Pareek, Saumya and Goncalves, Jorge and Johal, Wafa},
  title = {Robot-Assisted Decision-Making: Unveiling the Role of Uncertainty Visualisation and Embodiment},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  year = {2024},
  month = {May},
  dates = {11--16},
  location = {Honolulu, HI, USA},
  acmDOI = {10.1145/3613904.3642911},
  acmISBN = {979-8-4007-0330-0/24/05},
  publisher = {ACM},
  pdf = {https://chri-lab.github.io/files/papers/schombs2024.pdf},
  selected = 	 {yes}
}

@article{schombs2024facevis,
  title={FaceVis: Exploring a Robot’s Face for Affective Visualisation Design},
  author={Sch{\"o}mbs, Sarah and Pan, Jiahe and Zhang, Yan and Goncalves, Jorge and Johal, Wafa},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  pdf = {https://chri-lab.github.io/files/papers/schombs2024b.pdf},
  year={2024}, 
  video = {https://youtu.be/Q1H0tA2EWy8},
  website = {https://sites.google.com/view/facevis/home}
  selected = 	 {yes}
}

@inproceedings{admoni2024,
author = {Admoni, Henny and Johal, Wafa and Szafir, Daniel and Sandygulova, Anara},
title = {Designing an Introductory HRI Course},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638165},
doi = {10.1145/3610978.3638165},
abstract = {Human-robot interaction is now an established discipline. Dozens of HRI courses exist at universities worldwide, and some institutions even offer degrees in HRI. However, although many students are being taught HRI, there is no agreed-upon curriculum for an introductory HRI course. In this workshop, we aim to reach community consensus on what should be covered in such a course. Through interactive activities like panels, breakout discussions, and syllabus design, workshop participants will explore the many topics and pedagogical approaches for teaching HRI. They will then distill their findings into a single example introductory HRI curriculum. Output from this workshop will include a short paper explaining this curriculum and an example syllabus that can be used and adapted by HRI educators.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1302–1304},
numpages = {3},
keywords = {human-robot interaction, pedagogy},
location = {Boulder,CO,USA},
pdf = {https://chri-lab.github.io/files/papers/admoni2024.pdf},
series = {HRI '24}
}

@inproceedings{Yadollahi2024,
author = {Yadollahi, Elmira and Romeo, Marta and Dogan, Fethiye Irmak and Johal, Wafa and De Graaf, Maartje and Levy-Tzedek, Shelly and Leite, Iolanda},
title = {Explainability for Human-Robot Collaboration},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638154},
pdf = {https://chri-lab.github.io/files/papers/yadollahi.pdf},
doi = {10.1145/3610978.3638154},
abstract = {In human-robot collaboration, explainability bridges the communication gap between complex machine functionalities and humans. An active area of investigation in robotics and AI is understanding and generating explanations that can enhance collaboration and mutual understanding between humans and machines. A key to achieving such seamless collaborations is understanding end-users, whether naive or expert, and tailoring explanation features that are intuitive, user-centred, and contextually relevant. Advancing on the topic not only includes modelling humans' expectations for generating the explanations but also requires the development of metrics to evaluate generated explanations and assess how effectively autonomous systems communicate their intentions, actions, and decision-making rationale. This workshop is designed to tackle the nuanced role of explainability in enhancing the efficiency, safety, and trust in human-robot collaboration. It aims to initiate discussions on the importance of generating and evaluating explainability features developed in autonomous agents. Simultaneously, it addresses various challenges, including bias in explainability and downsides of explainability and deception in human-robot interaction.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1364–1366},
numpages = {3},
keywords = {XAI, explainable robotics, human-centered robot explanations},
location = {Boulder,CO,USA},
series = {HRI '24}
}

%%%%% 2023

@inproceedings{tozadore2023robots,
  title={Robots for Learning 7 (R4L) A Look from Stakeholders' Perspective},
  author={Tozadore, Daniel C and Nasir, Jauwairia and Gillet, Sarah and van den Berghe, Rianne and Guneysu, Arzu and Johal, Wafa},
  booktitle={Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={935--937},
  year={2023}
}

@incollection{bruno2023culture,
  title={Culture in Social Robots for Education},
  author={Bruno, Barbara and Amirova, Aida and Sandygulova, Anara and Lugrin, Birgit and Johal, Wafa},
  booktitle={Cultural Robotics: Social Robots and Their Emergent Cultural Ecologies},
  pages={127--145},
  year={2023},
  publisher={Springer International Publishing Cham}
}

@inproceedings{phaijit2023user,
  title={User Interface Interventions for Improving Robot Learning from Demonstration},
  author={Phaijit, Ornnalin and Sammut, Claude and Johal, Wafa},
  booktitle={Proceedings of the 11th International Conference on Human-Agent Interaction},
  pdf = {https://chri-lab.github.io/files/papers/phaijit2021.pdf},
  pages={152--161},
  year={2023},
  selected = 	 {yes}
}

@inproceedings{gamboa2023championing,
  title={Championing Design Knowledge in Human-Drone Interaction Research},
  author={Gamboa, Mafalda and Ljungblad, Sara and Johal, Wafa and Mubin, Omar and Obaid, Mohammad},
  booktitle={Proceedings of the 11th International Conference on Human-Agent Interaction},
  pages={365--368},
  year={2023}
}


@inproceedings{liu2023speech,
  title={Speech-Gesture GAN: Gesture Generation for Robots and Embodied Agents},
  author={Liu, Carson Yu and Mohammadi, Gelareh and Song, Yang and Johal, Wafa},
  booktitle={2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages={405--412},
  year={2023},
  organization={IEEE}
}


%%%%% 2022
@inproceedings{phaijit2022let,
  title={Let’s Compete! The Influence of Human-Agent Competition and Collaboration on Agent Learning and Human Perception},
  author={Phaijit, Ornnalin and Sammut, Claude and Johal, Wafa},
  booktitle={Proceedings of the 10th International Conference on Human-Agent Interaction},
  pages={86--94},
  year={2022}
}

@misc{bartneck2022proceedings,
  title={Proceedings of the 10th International Conference on Human-Agent Interaction},
  author={Bartneck, Christoph and Kanda, Takayuki and Obaid, Mohammad and Johal, Wafa},
  year={2022},
  publisher={ACM}
}


@article{johal2022envisioning,
  title={Envisioning social drones in education},
  author={Johal, Wafa and Gatos, Do{\u{g}}a and Yantac, Asim Evren and Obaid, Mohammad},
  journal={Frontiers in Robotics and AI},
  volume={9},
  pages={666736},
  year={2022},
  publisher={Frontiers}
}

@inproceedings{obaid2022social,
  title={Social Drones for Health and Well-being},
  author={Obaid, Mohammad and Tatar, K{\i}van{\c{c}} and Wiberg, Mikael and Said, Alan and Rost, Mattias and Weilenmann, Alexandra and Johal, Wafa and Eyssel, Friederike},
  booktitle={Adjunct Proceedings of the 2022 Nordic Human-Computer Interaction Conference},
  pages={1--4},
  year={2022}
}

@article{johal2022robots,
  title={Robots for learning},
  author={Johal, Wafa and Belpaeme, Tony and Chetouani, Mohamed},
  journal={Frontiers in Robotics and AI},
  volume={9},
  pages={1050658},
  year={2022},
  publisher={Frontiers}
}

@article{ozgur2022effect,
  title = {The effect of gamified robot-enhanced training on motor performance in chronic stroke survivors},
  journal = {Heliyon},
  volume = {8},
  number = {11},
  pages = {e11764},
  year = {2022},
  issn = {2405-8440},
  doi = {https://doi.org/10.1016/j.heliyon.2022.e11764},
  url = {https://www.sciencedirect.com/science/article/pii/S2405844022030523},
  author = {Arzu Guneysu Ozgur and Maximilian J. Wessel and Jennifer K. Olsen and Andéol Geoffroy Cadic-Melchior and Valérie Zufferey and Wafa Johal and Giulia Dominijanni and Jean-Luc Turlan and Andreas Mühl and Barbara Bruno and Philippe Vuadens and Pierre Dillenbourg and Friedhelm C. Hummel},
  keywords = {Gamification, Robotics, Stroke, Motor rehabilitation, Robot-assisted training, Personalization},
  abstract = {Task-specific training constitutes a core element for evidence-based rehabilitation strategies targeted at improving upper extremity activity after stroke. Its combination with additional treatment strategies and neurotechnology-based solutions could further improve patients' outcomes. Here, we studied the effect of gamified robot-assisted upper limb motor training on motor performance, skill learning, and transfer with respect to a non-gamified control condition with a group of chronic stroke survivors. The results suggest that a gamified training strategy results in more controlled motor performance during the training phase, which is characterized by a higher accuracy (lower deviance), higher smoothness (lower jerk), but slower speed. The responder analyses indicated that mildly impaired patients benefited most from the gamification approach. In conclusion, gamified robot-assisted motor training, which is personalized to the individual capabilities of a patient, constitutes a promising investigational strategy for further improving motor performance after a stroke.}
  }

%%%%% 2021


@inproceedings{ingle2021,
  title           = {The Valley of non-Distraction: Effect of Robot's Human-likeness on Perception Load},
  year            = {2021},
  author          = {Ingle, Daisy and Marcus, Nadine and Johal, Wafa},
  booktitle       = {Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction (HRI '21 Companion), March 8--11, 2021, Boulder,CO, USA},
  publisher = {Association for Computing Machinery},
  abstract            = {"Previous research in psychology has found that human faces have the capability of being more distracting under high perceptual load conditions compared to non-face objects. 
This project aims to assess the distracting potential of robot faces based on their human-likeliness. As a first step, this paper reports on our initial findings based on an online study.
We used a letter search task where participants had to search for a target letter within a circle of 6 letters, whilst an irrelevant distractor image was also present. 
The results of our experiment replicated previous results with human faces and non-face objects. Additionally, in the tasks where the irrelevant distractors are images of robot faces, the human-likeness of the robot influenced the response time (RT). 
Interestingly, the robot Alter produced results significantly different than all other distractor robots. 
The outcome of this is a distraction model related to human-likeness of robots. Our results show the impact of anthropomorphism on distracting potential and thus should be taken into account when designing robots."},
  keywords = {anthropomorphism, robot design, human-likeness, perception load},
  doi = {10.1145/3434074.3447137}
}


@misc{ogawa2021proceedings,
  title={Proceedings of the 9th International Conference on Human-Agent Interaction},
  author={Ogawa, Kohei and Yonezawa, Tomoko and Lucas, Gale M and Osawa, Hirotaka and Johal, Wafa and Shiomi, Masahiro},
  year={2021},
  publisher={ACM}
}

%%%%% 2020
@article{johal2020research,
  title={Research Trends in Social Robots for Learning},
  author={Johal, Wafa},
  journal={Current Robotics Reports},
  pages={1--9},
  year={2020},
  publisher={Springer International Publishing},
  selected = 	 {yes}
}

@inproceedings{yadollahi2020exploring,
  title={Exploring the Role of Perspective Taking in Educational Child-Robot Interaction},
  author={Yadollahi, Elmira and Couto, Marta and Johal, Wafa and Dillenbourg, Pierre and Paiva, Ana},
  booktitle={International Conference on Artificial Intelligence in Education},
  pages={346--351},
  year={2020},
  organization={Springer, Cham}
}

@article{gargot2020acquisition,
  title={Acquisition of handwriting in children with and without dysgraphia: A computational approach},
  author={Gargot, Thomas and Asselborn, Thibault and Pellerin, Hugues and Zammouri, Ingrid and M. Anzalone, Salvatore and Casteran, Laurence and Johal, Wafa and Dillenbourg, Pierre and Cohen, David and Jolly, Caroline},
  journal={Plos one},
  volume={15},
  number={9},
  pages={e0237575},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{johal2020Swarm,
author = {Johal, Wafa and Peng, Yu and Mi, Haipeng},
title = {Swarm Robots in Education: A Review of Challenges and Opportunities},
year = {2020},
isbn = {9781450380546},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406499.3418755},
doi = {10.1145/3406499.3418755},
abstract = {This study reviews published scientific literature on the use of swarm robots for education purposes in the last ten years. It focuses on user studies involving robotics swarm in order to identify the potential contributions of the incorporation of swarm robots as an educational tool and insight future research. We consider here the appearance of swarm robots, the curriculum of the experimental task and the interaction modalities between learners and robots. The outcomes of the literature review are discussed in terms of their existing challenges and opportunities for guiding researchers, educators, and practitioners.},
booktitle = {Proceedings of the 8th International Conference on Human-Agent Interaction},
pages = {272–274},
numpages = {3},
keywords = {educational tool, swarm robots, literature review, learning, multi-robot},
location = {Virtual Event, USA},
series = {HAI '20}
}

@article{gargot2020p,
  title={P. 114 Automatic assessment of motors impairments in autism spectrum disorders: a systematic review},
  author={Gargot, T and Archambault, D and Chetouani, M and Cohen, D and Johal, W and Anzalone, SM},
  journal={European Neuropsychopharmacology},
  volume={40},
  pages={S71--S72},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{chibaudel2020,
author = {Chibaudel, Quentin and Johal, Wafa and Oriola, Bernard and J-M Mac\'{e}, Marc and Dillenbourg, Pierre and Tartas, Val\'{e}rie and Jouffrais, Christophe},
title = {"If You've Gone Straight, Now, You Must Turn Left" - Exploring the Use of a Tangible Interface in a Collaborative Treasure Hunt for People with Visual Impairments},
year = {2020},
isbn = {9781450371032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373625.3417020},
doi = {10.1145/3373625.3417020},
abstract = {Tangible User Interfaces (TUI) have been found to be relevant tools for collaborative learning by providing a shared workspace and enhancing joint visual attention. Researchers have explored the use of TUIs in a variety of curricular activities and found them particularly interesting for spatial exploration. However, very few studies have explored how TUIs could be used as a collaborative medium for people with visual impairments (VIs). In this study, we investigated the effect of tangible interaction (a small tangible robot) in a spatial collaborative task (a treasure hunt) involving two people with VIs. The aim was to evaluate the impact of the design of the TUI on the collaboration and the strategies used to perform the task. The experiment involved six dyads of people with VIs. The results showed that the collaboration was impacted by the interaction design and open interesting perspectives on the design of collaborative games for people with VIs.},
booktitle = {The 22nd International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {19},
numpages = {10},
keywords = {Spatial cognition, Game, Wayfinding, Robots, Non-visual interaction, Maps, Learning, Haptics, 3D model},
location = {Virtual Event, Greece},
series = {ASSETS '20}
}

@ARTICLE{zhanel2020,
AUTHOR={Zhexenova, Zhanel and Amirova, Aida and Abdikarimova, Manshuk and Kudaibergenov, Kuanysh and Baimakhan, Nurakhmet and Tleubayev, Bolat and Asselborn, Thibault and Johal, Wafa and Dillenbourg, Pierre and CohenMiller, Anna and Sandygulova, Anara},   
TITLE={A Comparison of Social Robot to Tablet and Teacher in a New Script Learning Context},      
JOURNAL={Frontiers in Robotics and AI},      
VOLUME={7},      
PAGES={99},     
YEAR={2020},        
URL={https://www.frontiersin.org/article/10.3389/frobt.2020.00099},       
DOI={10.3389/frobt.2020.00099},      	
ISSN={2296-9144},    
ABSTRACT={This research occurred in a special context where Kazakhstan's recent decision to switch from Cyrillic to the Latin-based alphabet has resulted in challenges connected to teaching literacy, addressing a rare combination of research hypotheses and technical objectives about language learning. Teachers are not necessarily trained to teach the new alphabet, and this could result in a challenge for children with learning difficulties. Prior research studies in Human-Robot Interaction (HRI) have proposed the use of a robot to teach handwriting to children (Hood et al., <xref ref-type="bibr" rid="B28">2015</xref>; Lemaignan et al., <xref ref-type="bibr" rid="B44">2016</xref>). Drawing on the Kazakhstani case, our study takes an interdisciplinary approach by bringing together smart solutions from robotics, computer vision areas, and educational frameworks, language, and cognitive studies that will benefit diverse groups of stakeholders. In this study, a human-robot interaction application is designed to help primary school children learn both a newly-adopted script and also its handwriting system. The setup involved an experiment with 62 children between the ages of 7–9 years old, across three conditions: a robot and a tablet, a tablet only, and a teacher. Based on the paradigm—learning by teaching—the study showed that children improved their knowledge of the Latin script by interacting with a robot. Findings reported that children gained similar knowledge of a new script in all three conditions without gender effect. In addition, children's likeability ratings and positive mood change scores demonstrate significant benefits favoring the robot over a traditional teacher and tablet only approaches.}
}








